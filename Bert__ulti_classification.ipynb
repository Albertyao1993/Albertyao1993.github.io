{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert  _ulti_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IqD9yRZg2Pc20JLsNXm3zklym1vwmQpn",
      "authorship_tag": "ABX9TyM6iurTEWTudayhrOrvN58V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Albertyao1993/Albertyao1993.github.io/blob/master/Bert__ulti_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is first version for multi-classification with BERT and  in original form"
      ],
      "metadata": {
        "id": "hcDqcDjfrL8q"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISLgVlqE03p0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c08879-8df2-494d-eeef-0455714f624b"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install Ipython "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: Ipython in /usr/local/lib/python3.7/dist-packages (5.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from Ipython) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from Ipython) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from Ipython) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from Ipython) (57.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from Ipython) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from Ipython) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from Ipython) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from Ipython) (1.0.18)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->Ipython) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->Ipython) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->Ipython) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGoXv92OyTEq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "lzl-2ABvy_7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/Othercomputers/我的 MacBook Pro (1)/Documents/GitHub/neural_symbolic_FG/training/kn1_data.csv\")\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "XvmHRx9hy171",
        "outputId": "28bf4a0a-cd99-49d3-8d66-e680eef7ef7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3848f2d4-25d3-4c7f-9089-c3be65ed3375\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reference_answer</th>\n",
              "      <th>response</th>\n",
              "      <th>feedback</th>\n",
              "      <th>score</th>\n",
              "      <th>verification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>No submission. \\n\\t</td>\n",
              "      <td>The response is empty.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Incorrect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>The reverse forwarding each router has the inf...</td>\n",
              "      <td>The response is partially correct as it does n...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>Partially correct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>Reverse Path Forwarding and Reverse Path Broad...</td>\n",
              "      <td>The response correctly explains RPF and RPB an...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Correct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>Reverse path forwarding ensures a loop-free fo...</td>\n",
              "      <td>The response is partially correct. The purpose...</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Partially correct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>The purpose of Reverse Path Forwarding (RPF) i...</td>\n",
              "      <td>The response correctly answers the purpose and...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Correct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>Reverse Path Forwarding and Reverse Path Broa...</td>\n",
              "      <td>The response correctly answers the purpose and...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Correct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>Reverse Path Forwarding and Revers Path Broad...</td>\n",
              "      <td>The purpose of Reverse Path Forwarding and Rev...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>Partially correct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>Reverse Path Forwarding and Reverse Path Broad...</td>\n",
              "      <td>The response correctly explains RPF and RPB. H...</td>\n",
              "      <td>0.7</td>\n",
              "      <td>Partially correct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>Empty submission.\\n\\t</td>\n",
              "      <td>The response is empty.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Incorrect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>Reverse Path Forwarding (RPF) and Reverse Path...</td>\n",
              "      <td>The response does not state why RPF and RPB ar...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>Partially correct</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3848f2d4-25d3-4c7f-9089-c3be65ed3375')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3848f2d4-25d3-4c7f-9089-c3be65ed3375 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3848f2d4-25d3-4c7f-9089-c3be65ed3375');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    reference_answer  ...       verification\n",
              "0  \\nPurpose: Both implement a more efficient kin...  ...          Incorrect\n",
              "1  \\nPurpose: Both implement a more efficient kin...  ...  Partially correct\n",
              "2  \\nPurpose: Both implement a more efficient kin...  ...            Correct\n",
              "3  \\nPurpose: Both implement a more efficient kin...  ...  Partially correct\n",
              "4  \\nPurpose: Both implement a more efficient kin...  ...            Correct\n",
              "5  \\nPurpose: Both implement a more efficient kin...  ...            Correct\n",
              "6  \\nPurpose: Both implement a more efficient kin...  ...  Partially correct\n",
              "7  \\nPurpose: Both implement a more efficient kin...  ...  Partially correct\n",
              "8  \\nPurpose: Both implement a more efficient kin...  ...          Incorrect\n",
              "9  \\nPurpose: Both implement a more efficient kin...  ...  Partially correct\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = pd.DataFrame()\n",
        "df_data['content'] = df['reference_answer'] + df['response']\n",
        "df_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VkGXd1NozT5c",
        "outputId": "3163e98b-0943-412f-9471-8163ea1ce789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-910137d8-8ee1-4b18-9111-23c9cf8678c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-910137d8-8ee1-4b18-9111-23c9cf8678c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-910137d8-8ee1-4b18-9111-23c9cf8678c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-910137d8-8ee1-4b18-9111-23c9cf8678c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             content\n",
              "0  \\nPurpose: Both implement a more efficient kin...\n",
              "1  \\nPurpose: Both implement a more efficient kin...\n",
              "2  \\nPurpose: Both implement a more efficient kin...\n",
              "3  \\nPurpose: Both implement a more efficient kin...\n",
              "4  \\nPurpose: Both implement a more efficient kin..."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# le = LabelEncoder()\n",
        "# le.fit(df.verification)\n",
        "# le.classes_\n",
        "# labels = le.transform(df.verification)\n"
      ],
      "metadata": {
        "id": "TPS45qxPzh_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_labels = pd.get_dummies(df['verification'])\n",
        "one_hot_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_Jbo0zrPFROF",
        "outputId": "382df756-459e-4c91-82c2-bdcdff10fd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f9d47b0e-17f0-401e-b113-5fd22109c40a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Correct</th>\n",
              "      <th>Incorrect</th>\n",
              "      <th>Partially correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1471</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1472</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1473</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1474</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1475</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1476 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9d47b0e-17f0-401e-b113-5fd22109c40a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9d47b0e-17f0-401e-b113-5fd22109c40a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9d47b0e-17f0-401e-b113-5fd22109c40a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Correct  Incorrect  Partially correct\n",
              "0           0          1                  0\n",
              "1           0          0                  1\n",
              "2           1          0                  0\n",
              "3           0          0                  1\n",
              "4           1          0                  0\n",
              "...       ...        ...                ...\n",
              "1471        1          0                  0\n",
              "1472        0          0                  1\n",
              "1473        0          0                  1\n",
              "1474        0          1                  0\n",
              "1475        0          1                  0\n",
              "\n",
              "[1476 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_data['labels'] = labels\n",
        "# df_data = pd.concat([df_data, one_hot_labels],copy=True)\n",
        "# df_data.head(10)\n",
        "df_data = pd.concat([df_data, one_hot_labels], axis=1)\n",
        "df_data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NS6e17-W0fvc",
        "outputId": "9610b5b9-6d39-4674-b604-f1ada74aec8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1f61d89e-ee44-4d3f-b737-4864fdd76185\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>Correct</th>\n",
              "      <th>Incorrect</th>\n",
              "      <th>Partially correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f61d89e-ee44-4d3f-b737-4864fdd76185')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f61d89e-ee44-4d3f-b737-4864fdd76185 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f61d89e-ee44-4d3f-b737-4864fdd76185');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             content  ...  Partially correct\n",
              "0  \\nPurpose: Both implement a more efficient kin...  ...                  0\n",
              "1  \\nPurpose: Both implement a more efficient kin...  ...                  1\n",
              "2  \\nPurpose: Both implement a more efficient kin...  ...                  0\n",
              "3  \\nPurpose: Both implement a more efficient kin...  ...                  1\n",
              "4  \\nPurpose: Both implement a more efficient kin...  ...                  0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display(df_data.labels.unique())\n",
        "# display(le.classes_)"
      ],
      "metadata": {
        "id": "DywhOQjE09tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data.iloc[0][-3:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyJM2Li7bdCa",
        "outputId": "d62cdda2-db13-43ab-ab2c-ce7a320420ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Correct              0\n",
              "Incorrect            1\n",
              "Partially correct    0\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Data Loader"
      ],
      "metadata": {
        "id": "c-bPmuHY2QnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CN1_Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, data, tokenizer, max_length = 256) -> None:\n",
        "      super().__init__()\n",
        "      \n",
        "      self.data = data\n",
        "      self.tokenizer = tokenizer,\n",
        "      self.max_length = max_length\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = self.data.iloc[idx]\n",
        "    content = item['content']\n",
        "    label = torch.tensor(item[-3:], dtype=torch.float32)\n",
        "\n",
        "    input = tokenizer(content,\n",
        "                      padding='max_length', \n",
        "                      truncation=True,\n",
        "                      max_length=self.max_length, \n",
        "                      return_tensors='pt'\n",
        "                      )\n",
        "\n",
        "    return {\n",
        "        'content' : content,\n",
        "        'input_ids': input['input_ids'],\n",
        "        'attention_mask' : input['attention_mask'],\n",
        "        'label' : label\n",
        "    }\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "RvCcxjbc1Ko_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PRE_TRAINED_MODEL = 'bert-base-uncased'\n",
        "PRE_TRAINED_MODEL = 'distilbert-base-uncased'"
      ],
      "metadata": {
        "id": "rS4ixOr1cdU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(PRE_TRAINED_MODEL)"
      ],
      "metadata": {
        "id": "RMKbub0t4ntu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = df_data[:5]\n",
        "sample_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nqpXdRRd4yAk",
        "outputId": "ddb52aff-96b0-4a90-b0ee-07ec0dc73d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2ea95c57-eff6-4395-b41d-74f058bf5b0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>Correct</th>\n",
              "      <th>Incorrect</th>\n",
              "      <th>Partially correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nPurpose: Both implement a more efficient kin...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ea95c57-eff6-4395-b41d-74f058bf5b0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ea95c57-eff6-4395-b41d-74f058bf5b0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ea95c57-eff6-4395-b41d-74f058bf5b0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             content  ...  Partially correct\n",
              "0  \\nPurpose: Both implement a more efficient kin...  ...                  0\n",
              "1  \\nPurpose: Both implement a more efficient kin...  ...                  1\n",
              "2  \\nPurpose: Both implement a more efficient kin...  ...                  0\n",
              "3  \\nPurpose: Both implement a more efficient kin...  ...                  1\n",
              "4  \\nPurpose: Both implement a more efficient kin...  ...                  0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ds = CN1_Dataset(sample_data, tokenizer)\n",
        "# dl = DataLoader(ds, batch_size=16)\n",
        "# sample = next(iter(dl))\n",
        "# sample.keys()"
      ],
      "metadata": {
        "id": "G9V6WutW86z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train test split"
      ],
      "metadata": {
        "id": "M08WDg8-BZXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_len = int(0.8 * len(df_data))\n",
        "val_len = len(df_data) - train_len\n",
        "display(train_len)\n",
        "display(val_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "SDaQm9URBDB0",
        "outputId": "33f61bb9-d4ab-4b6d-8707-c31194351b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1180"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Sj1ewWAdrTQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "ds = CN1_Dataset(df_data, tokenizer)\n",
        "ds_train, ds_val = random_split(ds,[train_len, val_len], generator=torch.Generator().manual_seed(42))"
      ],
      "metadata": {
        "id": "78tJ31AZCjhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl_train = DataLoader(ds_train, batch_size=32,shuffle=True, num_workers=2)\n",
        "dl_val = DataLoader(ds_val, batch_size=32, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "BXpUmUoGDOKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OJlqDVXqJX0-",
        "outputId": "d7da6f69-ce5a-4fba-89cb-e9f76281a2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', problem_type='multi_label_classification', num_labels=3, output_attentions=False, output_hidden_states=False)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL, num_labels=3, output_attentions=False, output_hidden_states=False)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c6-bBaMFP7R",
        "outputId": "ad6bd408-3de6-42e2-d4a0-673f6ccded2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "EPOECHE = 100\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps= len(dl_train)*EPOECHE\n",
        "    # num_warmp_steps=0,\n",
        "    # num_training_steps=len(dl_train) * EPOECHE\n",
        ")\n",
        "\n",
        "history = defaultdict(list)\n",
        "\n",
        "loss_fn = torch.nn.BCELoss().to(device)\n",
        "\n",
        "\n",
        "for epoche in range(EPOECHE):\n",
        "\n",
        "  ## trainging loop\n",
        "  model.train()\n",
        "\n",
        "  train_losses = []\n",
        "  train_correct_preds = 0\n",
        "  for data in dl_train:\n",
        "    input_ids = data['input_ids'].squeeze(1).to(device)\n",
        "    attention_mask = data['attention_mask'].squeeze(1).to(device)\n",
        "    \n",
        "    label = data['label'].to(device)\n",
        "    # print(torch.argmax(label, dim=1))\n",
        "    output = model(input_ids, attention_mask,return_dict=True)\n",
        "    # output = model(**inputs)\n",
        "    # preds = torch.argmax(output.logits, dim=1)\n",
        "    preds = torch.nn.functional.softmax(output.logits, dim=-1)\n",
        "    # print(preds)\n",
        "    # break\n",
        "    train_loss = loss_fn(preds, label)\n",
        "\n",
        "    train_correct_preds += torch.sum(torch.argmax(preds, dim=1) == torch.argmax(label, dim=1))\n",
        "    # print(torch.argmax(preds, dim=1))\n",
        "    # print('-'*30)\n",
        "    # print(torch.argmax(label, dim=1))\n",
        "    # print(train_correct_preds)\n",
        "    \n",
        "    train_losses.append(train_loss.item())\n",
        "\n",
        "    train_loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  train_mean_loss = np.mean(train_losses)\n",
        "  train_accuracy = train_correct_preds / len(ds_train)\n",
        "\n",
        "  # print(f' training {epoche +1} / {EPOECHE}')\n",
        "  # print('*' * 50)\n",
        "  # print(f'training loss is {train_mean_loss},')\n",
        "  # print(f'trainging accuracy is {train_accuracy}')\n",
        "  # print('*' * 50)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  val_losses = []\n",
        "  val_correct_preds = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in dl_val:\n",
        "      input_ids = data['input_ids'].squeeze(1).to(device)\n",
        "      attention_mask = data['attention_mask'].squeeze(1).to(device)\n",
        "      label = data['label'].to(device)\n",
        "\n",
        "      output = model(input_ids, attention_mask, return_dict=True)\n",
        "      val_pred = torch.nn.functional.softmax(output.logits, dim=-1)\n",
        "\n",
        "      val_loss = loss_fn(val_pred, label)\n",
        "      val_losses.append(val_loss.item())\n",
        "      \n",
        "      val_correct_preds += torch.sum(torch.argmax(val_pred, dim=1) == torch.argmax(label, dim=1))\n",
        "      # print(\"#\"*50)\n",
        "      # print(torch.argmax(val_pred, dim=1))\n",
        "      # print('#'*50)\n",
        "      # print(torch.argmax(label, dim=1))\n",
        "      # print('#'*50)\n",
        "      # print(val_correct_preds)\n",
        "      # break\n",
        "    \n",
        "    val_mean_loss = np.mean(val_losses)\n",
        "    val_accuracy = val_correct_preds / len(ds_val)\n",
        "\n",
        "\n",
        "  history['train_loss'].append(train_mean_loss)\n",
        "  history['train_accuracy'].append(train_accuracy)\n",
        "  history['val_loss'].append(val_mean_loss)\n",
        "  history['val_accuracy'].append(val_accuracy)\n",
        "\n",
        "  print(f' training {epoche +1} / {EPOECHE}')\n",
        "  print('*' * 50)\n",
        "  print(f'training loss is: {train_mean_loss}, val loss is: {val_mean_loss}')\n",
        "  print(f'trainging accuracy is {train_accuracy}, val accuracy is: {val_accuracy}')\n",
        "  print('*' * 50)\n",
        "  # print(f'val loss is {val_mean_loss}')\n",
        "  # print(f'val accuracy is {val_accuracy}')\n",
        "  # print('*' * 50)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4c-4uU2Kwu_",
        "outputId": "2f22bcce-1810-41e8-d5f5-5ad15e1f5ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " training 1 / 100\n",
            "**************************************************\n",
            "training loss is: 0.5256456152812855, val loss is: 0.4483996510505676\n",
            "trainging accuracy is 0.5923728942871094, val accuracy is: 0.6452702879905701\n",
            "**************************************************\n",
            " training 2 / 100\n",
            "**************************************************\n",
            "training loss is: 0.4077918175104502, val loss is: 0.3541849464178085\n",
            "trainging accuracy is 0.7161017060279846, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 3 / 100\n",
            "**************************************************\n",
            "training loss is: 0.35680686460958944, val loss is: 0.3487180292606354\n",
            "trainging accuracy is 0.7559322118759155, val accuracy is: 0.7702702879905701\n",
            "**************************************************\n",
            " training 4 / 100\n",
            "**************************************************\n",
            "training loss is: 0.29979266588752335, val loss is: 0.4191034346818924\n",
            "trainging accuracy is 0.7932203412055969, val accuracy is: 0.7398648858070374\n",
            "**************************************************\n",
            " training 5 / 100\n",
            "**************************************************\n",
            "training loss is: 0.24494800656228452, val loss is: 0.42236778438091277\n",
            "trainging accuracy is 0.8364406824111938, val accuracy is: 0.7466216683387756\n",
            "**************************************************\n",
            " training 6 / 100\n",
            "**************************************************\n",
            "training loss is: 0.19984895433928515, val loss is: 0.5856415718793869\n",
            "trainging accuracy is 0.8745762705802917, val accuracy is: 0.7364864945411682\n",
            "**************************************************\n",
            " training 7 / 100\n",
            "**************************************************\n",
            "training loss is: 0.17048109725520416, val loss is: 0.5203102126717567\n",
            "trainging accuracy is 0.8847457766532898, val accuracy is: 0.7229729890823364\n",
            "**************************************************\n",
            " training 8 / 100\n",
            "**************************************************\n",
            "training loss is: 0.15653992947694417, val loss is: 0.5705480024218559\n",
            "trainging accuracy is 0.8999999761581421, val accuracy is: 0.75\n",
            "**************************************************\n",
            " training 9 / 100\n",
            "**************************************************\n",
            "training loss is: 0.1408474568176914, val loss is: 0.5238209873437881\n",
            "trainging accuracy is 0.9050847291946411, val accuracy is: 0.7229729890823364\n",
            "**************************************************\n",
            " training 10 / 100\n",
            "**************************************************\n",
            "training loss is: 0.12616603106663032, val loss is: 0.6268745183944702\n",
            "trainging accuracy is 0.9194915294647217, val accuracy is: 0.7263513803482056\n",
            "**************************************************\n",
            " training 11 / 100\n",
            "**************************************************\n",
            "training loss is: 0.12002366630209459, val loss is: 0.6208043158054352\n",
            "trainging accuracy is 0.9220339059829712, val accuracy is: 0.7398648858070374\n",
            "**************************************************\n",
            " training 12 / 100\n",
            "**************************************************\n",
            "training loss is: 0.11180669643186233, val loss is: 0.6660412967205047\n",
            "trainging accuracy is 0.9220339059829712, val accuracy is: 0.7331081032752991\n",
            "**************************************************\n",
            " training 13 / 100\n",
            "**************************************************\n",
            "training loss is: 0.1080951409766803, val loss is: 0.627582260966301\n",
            "trainging accuracy is 0.9220339059829712, val accuracy is: 0.7263513803482056\n",
            "**************************************************\n",
            " training 14 / 100\n",
            "**************************************************\n",
            "training loss is: 0.10811998936775569, val loss is: 0.6918430626392365\n",
            "trainging accuracy is 0.9254237413406372, val accuracy is: 0.7364864945411682\n",
            "**************************************************\n",
            " training 15 / 100\n",
            "**************************************************\n",
            "training loss is: 0.10327275288668838, val loss is: 0.6958327114582061\n",
            "trainging accuracy is 0.9271186590194702, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 16 / 100\n",
            "**************************************************\n",
            "training loss is: 0.10069289400770857, val loss is: 0.6543970555067062\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7364864945411682\n",
            "**************************************************\n",
            " training 17 / 100\n",
            "**************************************************\n",
            "training loss is: 0.10067484172916896, val loss is: 0.6776732832193375\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7331081032752991\n",
            "**************************************************\n",
            " training 18 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09778362104820239, val loss is: 0.7756115376949311\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7398648858070374\n",
            "**************************************************\n",
            " training 19 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09886807465070002, val loss is: 0.7367854475975036\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7466216683387756\n",
            "**************************************************\n",
            " training 20 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09898919984698296, val loss is: 0.7508472859859466\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 21 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09824051594714055, val loss is: 0.6768380932509899\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 22 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09818841184715967, val loss is: 0.6995904207229614\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7466216683387756\n",
            "**************************************************\n",
            " training 23 / 100\n",
            "**************************************************\n",
            "training loss is: 0.0972712797087592, val loss is: 0.6827927107922733\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7331081032752991\n",
            "**************************************************\n",
            " training 24 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09648250491433852, val loss is: 0.6987607479095459\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.75\n",
            "**************************************************\n",
            " training 25 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09607799210258432, val loss is: 0.807705608010292\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 26 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09632752548802544, val loss is: 0.7034723646938801\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7466216683387756\n",
            "**************************************************\n",
            " training 27 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09788825906611778, val loss is: 0.7752490609884262\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 28 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09620427549187396, val loss is: 0.727000542730093\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 29 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09752327238989843, val loss is: 0.7642827749252319\n",
            "trainging accuracy is 0.9279661178588867, val accuracy is: 0.7466216683387756\n",
            "**************************************************\n",
            " training 30 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09689099475036601, val loss is: 0.8236137568950653\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 31 / 100\n",
            "**************************************************\n",
            "training loss is: 0.0973231696297188, val loss is: 0.7705861061811448\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7466216683387756\n",
            "**************************************************\n",
            " training 32 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09602514558748619, val loss is: 0.8283409237861633\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 33 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09705804368934116, val loss is: 0.7469230979681015\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7398648858070374\n",
            "**************************************************\n",
            " training 34 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09636194248859947, val loss is: 0.7845421135425568\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 35 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09579612828187041, val loss is: 0.7551917225122452\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.75\n",
            "**************************************************\n",
            " training 36 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09675180509283736, val loss is: 0.8761445373296738\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7466216683387756\n",
            "**************************************************\n",
            " training 37 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09551022493758717, val loss is: 0.8109476894140244\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7466216683387756\n",
            "**************************************************\n",
            " training 38 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09628884418162743, val loss is: 0.7618678718805313\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7466216683387756\n",
            "**************************************************\n",
            " training 39 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09572044043877237, val loss is: 0.8137487411499024\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 40 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09639444997584498, val loss is: 0.743129412829876\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7466216683387756\n",
            "**************************************************\n",
            " training 41 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09614059268622785, val loss is: 0.7836947843432427\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 42 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09710031707544585, val loss is: 0.7685203313827514\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 43 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09669452130391791, val loss is: 0.8407071590423584\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 44 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09605459717882646, val loss is: 0.7583838701248169\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 45 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09570708256403639, val loss is: 0.8019018799066544\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 46 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09504729182132192, val loss is: 0.8520596385002136\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7398648858070374\n",
            "**************************************************\n",
            " training 47 / 100\n",
            "**************************************************\n",
            "training loss is: 0.0958963976921262, val loss is: 0.7938406020402908\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 48 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09505961150736422, val loss is: 0.7564786771312356\n",
            "trainging accuracy is 0.9305084347724915, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 49 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09516599570476525, val loss is: 1.0003559112548828\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.75\n",
            "**************************************************\n",
            " training 50 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09569958577284941, val loss is: 0.7681395821273327\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7601351737976074\n",
            "**************************************************\n",
            " training 51 / 100\n",
            "**************************************************\n",
            "training loss is: 0.0956660655604021, val loss is: 0.7743731528520584\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 52 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09555755188134876, val loss is: 0.8701839238405228\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.75\n",
            "**************************************************\n",
            " training 53 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09484057737564719, val loss is: 0.8619531333446503\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7601351737976074\n",
            "**************************************************\n",
            " training 54 / 100\n",
            "**************************************************\n",
            "training loss is: 0.095185052855192, val loss is: 0.7696459567872808\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 55 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09665367735952542, val loss is: 0.7722512230277061\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.75\n",
            "**************************************************\n",
            " training 56 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09572351507439807, val loss is: 0.7973554074764252\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 57 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09532826685824909, val loss is: 0.853398221731186\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.75\n",
            "**************************************************\n",
            " training 58 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09495521100187623, val loss is: 0.8504228442907333\n",
            "trainging accuracy is 0.9305084347724915, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 59 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09543652902986552, val loss is: 0.7494594071991741\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7466216683387756\n",
            "**************************************************\n",
            " training 60 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09414323599304299, val loss is: 0.8073906302452087\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 61 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09436781467819536, val loss is: 0.8070496052503586\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 62 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09437440698211258, val loss is: 0.8640523314476013\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.75\n",
            "**************************************************\n",
            " training 63 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09550169681677141, val loss is: 0.8168504118919373\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 64 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09492864041916423, val loss is: 0.8518974721431732\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7432432770729065\n",
            "**************************************************\n",
            " training 65 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09502788059212067, val loss is: 0.8397469043731689\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7466216683387756\n",
            "**************************************************\n",
            " training 66 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09465344581199256, val loss is: 0.7904943317174912\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7601351737976074\n",
            "**************************************************\n",
            " training 67 / 100\n",
            "**************************************************\n",
            "training loss is: 0.0953199331824844, val loss is: 0.9605101197957993\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7601351737976074\n",
            "**************************************************\n",
            " training 68 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09474164922092412, val loss is: 0.7997181653976441\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 69 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09474808148838379, val loss is: 0.8628876090049744\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 70 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09529319924075862, val loss is: 0.8592835664749146\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 71 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09543715135471241, val loss is: 0.9440836191177369\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 72 / 100\n",
            "**************************************************\n",
            "training loss is: 0.094667938890288, val loss is: 0.7921469002962113\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 73 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09520186096228458, val loss is: 0.8446496009826661\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 74 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09533015887781575, val loss is: 0.8149314880371094\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 75 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09595154432227483, val loss is: 0.8040604531764984\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 76 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09493875161216066, val loss is: 0.8568591430783272\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 77 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09518290210414578, val loss is: 0.7948542319238185\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 78 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09460336634436169, val loss is: 0.8097119480371475\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 79 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09528967315280759, val loss is: 0.8403546810150146\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 80 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09489863240034194, val loss is: 0.8488413989543915\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 81 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09440278448164463, val loss is: 0.790545704588294\n",
            "trainging accuracy is 0.9305084347724915, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 82 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09491435391120487, val loss is: 0.7916342667289428\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 83 / 100\n",
            "**************************************************\n",
            "training loss is: 0.0946847964078188, val loss is: 0.8827353894710541\n",
            "trainging accuracy is 0.9305084347724915, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 84 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09474285359720926, val loss is: 0.9057151198387146\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 85 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09478159223658007, val loss is: 0.8427670955657959\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 86 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09485511803949201, val loss is: 0.8621405988931656\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 87 / 100\n",
            "**************************************************\n",
            "training loss is: 0.0952136801505411, val loss is: 0.8062650442123414\n",
            "trainging accuracy is 0.9305084347724915, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 88 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09426942518031275, val loss is: 0.9133190035820007\n",
            "trainging accuracy is 0.9305084347724915, val accuracy is: 0.7567567825317383\n",
            "**************************************************\n",
            " training 89 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09497848490404116, val loss is: 0.8348943561315536\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7601351737976074\n",
            "**************************************************\n",
            " training 90 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09395020445053642, val loss is: 0.8615843206644058\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 91 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09489039296435343, val loss is: 0.8005183918401599\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 92 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09439143659295263, val loss is: 0.8994758546352386\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 93 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09495643284675237, val loss is: 0.8093156754970551\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 94 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09447485127964535, val loss is: 0.8028483599424362\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 95 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09465033097847088, val loss is: 0.8518084019422532\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 96 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09419401342401633, val loss is: 0.8700734496116638\n",
            "trainging accuracy is 0.9288135766983032, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 97 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09444406306421435, val loss is: 0.8594047993421554\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 98 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09376600752207073, val loss is: 0.7998596306890249\n",
            "trainging accuracy is 0.9305084347724915, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 99 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09468313377048518, val loss is: 0.8166879057884217\n",
            "trainging accuracy is 0.9305084347724915, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n",
            " training 100 / 100\n",
            "**************************************************\n",
            "training loss is: 0.09469104319106082, val loss is: 0.85211481153965\n",
            "trainging accuracy is 0.9296610355377197, val accuracy is: 0.7533783912658691\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history['train_loss'], label='train loss')\n",
        "plt.plot(history['val_loss'], label='validation loss')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "metadata": {
        "id": "vJcIWNXNObwI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "aa003281-985d-4411-a170-e5cefce4383e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history['train_accuracy'], label='train accuracy')\n",
        "plt.plot(history['val_accuracy'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "metadata": {
        "id": "m5fSG1yP5vnu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8acb4301-aab6-401a-b463-af881b620cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iS7MalZI00PS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}